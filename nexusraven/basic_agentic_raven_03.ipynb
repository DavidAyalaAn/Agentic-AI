{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee8fb938",
   "metadata": {},
   "source": [
    "# Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0cf13f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e6e99",
   "metadata": {},
   "source": [
    "# Model Client Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0141dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_host = \"http://host.docker.internal:11434\"\n",
    "ollama_model = 'nexusraven:latest'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb818d1e",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9988b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {\n",
    "    'patients' : {\n",
    "        'A00001' : {\n",
    "            'dni':'74324694A',\n",
    "            'name':'Fulgoroncio',\n",
    "            'age':35,\n",
    "            'clinical_records': [\n",
    "                {\n",
    "                    'record_id':'V00001',\n",
    "                    'date':'2024-11-15',\n",
    "                    #'patient_id': 'A00001',\n",
    "                    'disease_id': 'X00005',\n",
    "                    'treatment': 'Buy a hammer and carry everywhere to break the copy reference.',\n",
    "                    'status':'Healed',\n",
    "                    'observation':'She may need another solution in prision.'\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        'A00002' : {\n",
    "            'dni':'24336634A',\n",
    "            'name':'Petunia',\n",
    "            'age':27,\n",
    "            'clinical_records':[\n",
    "                {\n",
    "                    'record_id':'V00001',\n",
    "                    'date':'2024-11-15',\n",
    "                    #'patient_id': 'A00002',\n",
    "                    'disease_id': 'X00005',\n",
    "                    'treatment': 'Buy a hammer and carry everywhere to break the copy reference.',\n",
    "                    'status':'Healed',\n",
    "                    'observation':'She may need another solution in prision.'\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    'diseases' : {\n",
    "        'X00001' : {\n",
    "            'disease_name' : 'Invisible toy disorder',\n",
    "            'description': 'The person tends to loose members of toys. Also suffers from cognitive time jumps, as she forgots 10 minute lapses.'\n",
    "        },\n",
    "        'X00002' : {\n",
    "            'disease_name' : 'Sofacosis syndrome',\n",
    "            'description': 'Mental syndrome to get sofas placed in an exact location on images.'\n",
    "        },\n",
    "        'X00003' : {\n",
    "            'disease_name' : 'Spontaneous mattress somnambulism',\n",
    "            'description': 'The person awakes in another room, with a matrees moved from a room to another. In some cases the person develops a phobia to hear possible solutions.'\n",
    "        },\n",
    "        'X00004' : {\n",
    "            'disease_name' : 'Indian immune repulsive',\n",
    "            'description': 'The person naturally causes indian people to vanish or avoid responses to her inqueries. on its chronicle phase it generates unpleasent behaviors from greeks'\n",
    "        },\n",
    "        'X00005' : {\n",
    "            'disease_name' : 'Mirror Mimic Madness',\n",
    "            'description': 'The person believes they are a mirror and must copy the exact movements of whoever is in front of themâ€”even strangers in public.'\n",
    "        },\n",
    "        'X00006' : {\n",
    "            'disease_name' : 'Dramatic Slow-Mo Virus',\n",
    "            'symptoms': 'The infected person perceives their life as a dramatic movie and moves in slow motion during mundane tasks.'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f49ef",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b0667",
   "metadata": {},
   "source": [
    "\n",
    "## Pydantic Data Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d328f7",
   "metadata": {},
   "source": [
    "Pydantic classes are used only to create the definition for the arguments.\n",
    "\n",
    "In this case we also add tags ['...'] to descriptions to give more relevant information to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "114fda42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hospital_patients(BaseModel):\n",
    "    pass\n",
    "    \n",
    "class patient_clinical_record(BaseModel):\n",
    "    patient_id: str = Field(description='[patiend-identifier] System identifier of the patient.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191e1b18",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7a000",
   "metadata": {},
   "source": [
    "The tool tag is used to include the class descriptions to the functions. This option allows to create the scheme in a more organized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e57d5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(args_schema = hospital_patients)\n",
    "def get_hospital_patients() -> dict:\n",
    "    \"\"\"\n",
    "    [all-patients] This function retrieves the patients registered in the hospital.\n",
    "\n",
    "    Returns: A dictionary of the patients registered in the hospital.\n",
    "    \"\"\"\n",
    "    \n",
    "    patients = {\n",
    "        key: { attr:attr_data for attr,attr_data in data.items() if attr != 'clinical_records' }\n",
    "        for key,data in context['patients'].items()\n",
    "    }\n",
    "\n",
    "    return {'patients': patients}\n",
    "\n",
    "@tool(args_schema = patient_clinical_record)\n",
    "def get_patient_clinical_record(patient_id:str) -> dict:\n",
    "    '''\n",
    "    [clinical-info] Retrieves the clinical history of a patient by the sistem identifier, which has a numerical text portion.\n",
    "    \n",
    "    Returns: Dictionary with the clinical record of the requested patient.\n",
    "    \n",
    "    Args description:\n",
    "        patient_id (str): [patiend-identifier] System identifier of the patient.\n",
    "    '''\n",
    "    \n",
    "    if  patient_id in context['patients'].keys():\n",
    "        records = context['patients'].get(patient_id)['clinical_records']\n",
    "        return records\n",
    "    else:\n",
    "        print(\"No patient found with id {}\".format(patient_id))\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84086585",
   "metadata": {},
   "source": [
    "## Tool Schema Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9d2335b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'get_hospital_patients': StructuredTool(name='get_hospital_patients', description='[all-patients] This function retrieves the patients registered in the hospital.\\n\\nReturns: A dictionary of the patients registered in the hospital.', args_schema=<class '__main__.hospital_patients'>, func=<function get_hospital_patients at 0x72e0fd55fd80>),\n",
       " 'get_patient_clinical_record': StructuredTool(name='get_patient_clinical_record', description='[clinical-info] Retrieves the clinical history of a patient by the sistem identifier, which has a numerical text portion.\\n\\nReturns: Dictionary with the clinical record of the requested patient.\\n\\nArgs description:\\n    patient_id (str): [patiend-identifier] System identifier of the patient.', args_schema=<class '__main__.patient_clinical_record'>, func=<function get_patient_clinical_record at 0x72e0fd55fc40>)}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [\n",
    "    get_hospital_patients,\n",
    "    get_patient_clinical_record\n",
    "]\n",
    "\n",
    "function_map = {tool.name: tool for tool in tools}\n",
    "function_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f904540",
   "metadata": {},
   "source": [
    "# Agent Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f5ec8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "import re\n",
    "\n",
    "class mychat():\n",
    "    def __init__(self,tools):\n",
    "        #Tools\n",
    "        self.function_map = {tool.name:tool for tool in tools}\n",
    "        self.tools_schema = [convert_to_openai_function(tool) for tool in tools]\n",
    "        self.tools_prompt = self.build_tools_prompt()\n",
    "\n",
    "        #Prompt\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=self.tools_prompt),\n",
    "            MessagesPlaceholder(variable_name='chat_history'),\n",
    "            ('user','{user_query}')\n",
    "        ])\n",
    "        \n",
    "        #Model setup        \n",
    "        self.model = ChatOllama(\n",
    "            model=\"nexusraven:latest\",\n",
    "            base_url=ollama_host,\n",
    "            temperature=0.001\n",
    "        )\n",
    "        \n",
    "        self.chat_history = []\n",
    "        self.intermedium_steps = []\n",
    "        self.chain = self.prompt | self.model | RunnableLambda(self.parse_functions)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def conversation_chain(self,user_query):\n",
    "        print('Entered on function')\n",
    "        response = self.chain.invoke({\n",
    "            \"chat_history\": self.chat_history,\n",
    "            \"user_query\": user_query\n",
    "        })\n",
    "\n",
    "        self.chat_history.append(HumanMessage(content=user_query))\n",
    "        self.chat_history.extend(self.intermedium_steps)\n",
    "        self.chat_history.append(AIMessage(content=\"\\n\".join(map(str, response['result']))))\n",
    "        self.intermedium_steps = []\n",
    "        \n",
    "        print(self.chat_history)\n",
    "        \n",
    "        return response['result']\n",
    "    \n",
    "    \n",
    "    def clean_history(self):\n",
    "        self.chat_history = []\n",
    "        self.intermedium_steps = []\n",
    "        \n",
    "    def build_tools_prompt(self):   \n",
    "        function_prompt = ''\n",
    "        for funct in self.function_map.values():  \n",
    "            function_prompt += ( 'def {tool_name}({args}):\\n\"\"\"\\n{desc}\\n\"\"\"\\n\\n'.format(\n",
    "                tool_name = funct.name, \n",
    "                args = ','.join(['{}:{}'.format(key,data['type']) for key, data in funct.args.items() ]),\n",
    "                #args = inspect.signature(funct),\n",
    "                desc = funct.description\n",
    "            ))\n",
    "            \n",
    "        instruction_prompt = '''\n",
    "    Instructions:\n",
    "    - ONLY use the provided functions.\n",
    "    - DO NOT nest function calls.\n",
    "    - Use ONLY values that have already been returned in previous steps.\n",
    "    - Use the exact function name and parameters as defined.\n",
    "    - If no parameters are needed, call without arguments\n",
    "    - Output format must be exactly: Call: function_name(arguments)<bot_end>\n",
    "        '''\n",
    "        \n",
    "        system_prompt = function_prompt + instruction_prompt\n",
    "        \n",
    "        print('Returning prompt')\n",
    "        \n",
    "        return system_prompt\n",
    "    \n",
    "    def parse_functions(self, response):\n",
    "        \n",
    "        print('Ready to parse the response')\n",
    "        response_message = response.content\n",
    "        self.intermedium_steps.append(AIMessage(content=response.content))\n",
    "        \n",
    "        #We look for function calls located between the strings \"Call:\" and \"<bot_end>\"\n",
    "        matches = re.findall(r'Call:\\s*(\\w+)\\((.*?)\\)<bot_end>', response_message)\n",
    "\n",
    "        print(matches)\n",
    "        #We assure we got function calls in the response\n",
    "        results = []\n",
    "        if matches:\n",
    "            #This loop runs througth the sequence of functions included in the response\n",
    "            #for func in matches:\n",
    "            for func_name,args_text in matches:\n",
    "                try:\n",
    "                    #This executes our functions\n",
    "                    print(args_text)\n",
    "                    args = eval(f'dict({args_text})') if (args_text.strip()) and (args_text != 'null=null') else {}\n",
    "                    self.intermedium_steps.append(AIMessage(content='Called function: {}({})'.format(func_name,args_text)))\n",
    "                    \n",
    "                    result = self.function_map[func_name].run(args)\n",
    "                    results.append(result)\n",
    "                except Exception as e:\n",
    "                    result = \"Function call failed: {}\".format(func_name)\n",
    "                    results.append(result)\n",
    "        else:\n",
    "            results.append(\"No function calls found.\")\n",
    "        return {'result':results}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea1193b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning prompt\n",
      "Entered on function\n",
      "Ready to parse the response\n",
      "[('get_hospital_patients', 'null=null')]\n",
      "null=null\n",
      "[HumanMessage(content='can you get the patients of the hospital?', additional_kwargs={}, response_metadata={}), AIMessage(content=' \\nCall: get_hospital_patients(null=null)<bot_end> \\nThought: The function call `get_hospital_patients(null=null)` answers the question \"can you get the patients of the hospital?\" because it retrieves the patients registered in the hospital.\\n\\nThe `get_hospital_patients` function is defined to return a dictionary of the patients registered in the hospital, and the `null` parameter is used to indicate that no specific patient is being requested. Therefore, by calling `get_hospital_patients(null=null)`, we are asking for all the patients registered in the hospital.\\n\\nThe function call does not nest any other function calls, so it does not rely on any other functions or values returned by previous steps. It only uses the provided functions and parameters to retrieve the patients registered in the hospital.', additional_kwargs={}, response_metadata={}), AIMessage(content='Called function: get_hospital_patients({})', additional_kwargs={}, response_metadata={}), AIMessage(content=\"{'patients': {'A00001': {'dni': '74324694A', 'name': 'Fulgoroncio', 'age': 35}, 'A00002': {'dni': '24336634A', 'name': 'Petunia', 'age': 27}}}\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "chat = mychat(tools)\n",
    "resp = chat.conversation_chain('can you get the patients of the hospital?')\n",
    "\n",
    "#can you get the patients of the hospital?\n",
    "#show me the clinical record of fulgoroncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = chat.conversation_chain('show me the clinical record of fulgoroncio?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
